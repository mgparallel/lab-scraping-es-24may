{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Web Scraping\n",
    "\n",
    "Encontrar√°s en este cuaderno algunos ejercicios de web scraping para practicar tus habilidades de scraping usando `requests` y `Beautiful Soup`.\n",
    "\n",
    "**Consejos:**\n",
    "\n",
    "- Verifica el [c√≥digo de estado de la respuesta](https://http.cat/) para cada solicitud para asegurarte de haber obtenido el contenido previsto.\n",
    "- Observa el c√≥digo HTML en cada solicitud para entender el tipo de informaci√≥n que est√°s obteniendo y su formato.\n",
    "- Busca patrones en el texto de respuesta para extraer los datos/informaci√≥n solicitados en cada pregunta.\n",
    "- Visita cada URL y echa un vistazo a su fuente a trav√©s de Chrome DevTools. Necesitar√°s identificar las etiquetas HTML, nombres de clases especiales, etc., utilizados para el contenido HTML que se espera extraer.\n",
    "- Revisa los selectores CSS.\n",
    "\n",
    "### Recursos √ötiles\n",
    "- Documentaci√≥n de la [biblioteca Requests](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Doc de Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Lista de c√≥digos de estado HTTP](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [Conceptos b√°sicos de HTML](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [Conceptos b√°sicos de CSS](https://www.cssbasics.com/#page_start)\n",
    "\n",
    "#### Primero que todo, reuniendo nuestras herramientas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Nuevamente, recuerda limitar tu salida antes de la entrega para que tu c√≥digo no se pierda en la salida.**\n",
    "\n",
    "#### Desaf√≠o 1 - Descargar, analizar (usando BeautifulSoup) e imprimir el contenido de la p√°gina de Desarrolladores en Tendencia de GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_html=requests.get(url).text\n",
    "soup = BeautifulSoup(github_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muestra los nombres de los desarrolladores en tendencia recuperados en el paso anterior.\n",
    "\n",
    "Tu salida debe ser una lista de Python con los nombres de los desarrolladores. Cada nombre no debe contener ninguna etiqueta HTML.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. Descubre la etiqueta HTML y los nombres de clase usados para los nombres de los desarrolladores. Puedes lograr esto usando Chrome DevTools.\n",
    "\n",
    "1. Usa BeautifulSoup para extraer todos los elementos HTML que contienen los nombres de los desarrolladores.\n",
    "\n",
    "1. Utiliza t√©cnicas de manipulaci√≥n de cadenas para reemplazar espacios en blanco y saltos de l√≠nea (es decir, `\\n`) en el *texto* de cada elemento HTML. Usa una lista para almacenar los nombres limpios.\n",
    "\n",
    "1. Imprime la lista de nombres.\n",
    "\n",
    "Tu salida deber√≠a lucir como abajo (con nombres diferentes):\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (Á•ûÊ•ΩÂùÇË¶ö„ÄÖ)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sebastian Raschka',\n",
       " 'LangChain4j',\n",
       " 'Norman Maurer',\n",
       " 'doronz88',\n",
       " 'JJ Kasper',\n",
       " 'Miguel Beltran',\n",
       " 'Vik Paruchuri',\n",
       " 'Arthur',\n",
       " 'Holt Skinner',\n",
       " 'Huang Huang',\n",
       " 'Aliaksandr Valialkin',\n",
       " 'Massimiliano Pippi',\n",
       " 'Jack Lloyd',\n",
       " 'Rich Harris',\n",
       " 'Tobias Klauser',\n",
       " 'Lukas Masuch',\n",
       " 'Charlie Marsh',\n",
       " 'Steven Silvester',\n",
       " 'Matthias Seitz',\n",
       " 'Justin Lebar',\n",
       " 'Mattias Wadman',\n",
       " 'David Sherret',\n",
       " 'Gal Schlezinger',\n",
       " 'Mitchell Hashimoto',\n",
       " 'awaelchli']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_devp = soup.select('h1.h3 a.Link')\n",
    "\n",
    "list_name = []\n",
    "for name in names_devp:\n",
    "    list_name.append(name.get_text().strip())\n",
    "\n",
    "list_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 2 - Mostrar los repositorios de Python en tendencia en GitHub\n",
    "\n",
    "Los pasos para resolver este problema son similares al anterior, excepto que necesitas encontrar los nombres de los repositorios en lugar de los nombres de los desarrolladores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'\n",
    "datos2 = requests.get(f\"{url2}\").text\n",
    "soup2 = BeautifulSoup(datos2, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cover-agent',\n",
       " 'khoj',\n",
       " 'searxng',\n",
       " 'MiniCPM-V',\n",
       " 'CVE-2024-21683-RCE',\n",
       " 'omniglue',\n",
       " 'ungoogled-chromium',\n",
       " 'bisheng',\n",
       " 'nvda',\n",
       " 'ragflow',\n",
       " 'seismometer',\n",
       " 'core',\n",
       " 'accelerate',\n",
       " 'taipy',\n",
       " 'corenet',\n",
       " 'LaVague',\n",
       " 'gpt-researcher',\n",
       " 'krita-ai-diffusion',\n",
       " 'azure-sdk-for-python',\n",
       " 'unsloth',\n",
       " 'TagStudio',\n",
       " 'pathway',\n",
       " 'Python',\n",
       " 'Python-100-Days',\n",
       " 'sqlmesh']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup2.select('h2 a')\n",
    "\n",
    "repo_names = []\n",
    "for link in links:\n",
    "    repo_name = link.get_text().strip()\n",
    "    repo_names.append(repo_name.split('\\n')[2].strip())\n",
    "\n",
    "repo_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 3 - Mostrar todos los enlaces de im√°genes de la p√°gina de Wikipedia de Walt Disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "disney = requests.get(f\"{url3}\").text\n",
    "soup3 = BeautifulSoup(disney, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/static/images/icons/wikipedia.png',\n",
       " '/static/images/mobile/copyright/wikipedia-wordmark-en.svg',\n",
       " '/static/images/mobile/copyright/wikipedia-tagline-en.svg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Nuvola_apps_kaboodle.svg/16px-Nuvola_apps_kaboodle.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/20px-Commons-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/23px-Wikiquote-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/26px-Wikisource-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Mickey_Mouse_colored_%28head%29.svg/20px-Mickey_Mouse_colored_%28head%29.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " 'https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " '/static/images/footer/wikimedia-button.png',\n",
       " '/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = soup3.find_all('img')\n",
    "images_link = []\n",
    "\n",
    "for image in images:\n",
    "    if image.has_attr('src'):\n",
    "        images_link.append(image['src'])\n",
    "\n",
    "images_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 4 - Recuperar todos los enlaces a p√°ginas en Wikipedia que se refieren a alg√∫n tipo de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 ='https://en.wikipedia.org/wiki/Python' \n",
    "python = requests.get(f\"{url4}\").text\n",
    "soup4 = BeautifulSoup(python, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Main_Page',\n",
       " '/wiki/Wikipedia:Contents',\n",
       " '/wiki/Portal:Current_events',\n",
       " '/wiki/Special:Random',\n",
       " '/wiki/Wikipedia:About',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " '/wiki/Help:Contents',\n",
       " '/wiki/Help:Introduction',\n",
       " '/wiki/Wikipedia:Community_portal',\n",
       " '/wiki/Special:RecentChanges',\n",
       " '/wiki/Wikipedia:File_upload_wizard',\n",
       " '/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " '/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " '/w/index.php?title=Special:CreateAccount&returnto=Python',\n",
       " '/w/index.php?title=Special:UserLogin&returnto=Python',\n",
       " '/wiki/Special:MyContributions',\n",
       " '/wiki/Special:MyTalk',\n",
       " '#',\n",
       " '#Snakes',\n",
       " '#Computing',\n",
       " '#People',\n",
       " '#Roller_coasters',\n",
       " '#Vehicles',\n",
       " '#Weaponry',\n",
       " '#Other_uses',\n",
       " '#See_also',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86_(%D8%AA%D9%88%D8%B6%D9%8A%D8%AD)',\n",
       " 'https://az.wikipedia.org/wiki/Python_(d%C9%99qiql%C9%99%C5%9Fdirm%C9%99)',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://kn.wikipedia.org/wiki/%E0%B2%B9%E0%B3%86%E0%B2%AC%E0%B3%8D%E0%B2%AC%E0%B2%BE%E0%B2%B5%E0%B3%81',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python_(anlam_ayr%C4%B1m%C4%B1)',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " '/wiki/Python',\n",
       " '/wiki/Talk:Python',\n",
       " '/wiki/Python',\n",
       " '/w/index.php?title=Python&action=edit',\n",
       " '/w/index.php?title=Python&action=history',\n",
       " '/wiki/Python',\n",
       " '/w/index.php?title=Python&action=edit',\n",
       " '/w/index.php?title=Python&action=history',\n",
       " '/wiki/Special:WhatLinksHere/Python',\n",
       " '/wiki/Special:RecentChangesLinked/Python',\n",
       " '/wiki/Wikipedia:File_Upload_Wizard',\n",
       " '/wiki/Special:SpecialPages',\n",
       " '/w/index.php?title=Python&oldid=1213626445',\n",
       " '/w/index.php?title=Python&action=info',\n",
       " '/w/index.php?title=Special:CiteThisPage&page=Python&id=1213626445&wpFormIdentifier=titleform',\n",
       " '/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPython',\n",
       " '/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPython',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " '/w/index.php?title=Special:DownloadAsPdf&page=Python&action=show-download-screen',\n",
       " '/w/index.php?title=Python&printable=yes',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " '/wiki/Pythonidae',\n",
       " '/wiki/Python_(genus)',\n",
       " '/wiki/Python_(genus)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/wiki/PERQ#PERQ_3',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/wiki/Python_(codename)',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/wiki/Timon_of_Phlius',\n",
       " '/wiki/Pyton',\n",
       " '/wiki/Pithon',\n",
       " '/wiki/Category:Disambiguation_pages',\n",
       " '/wiki/Category:Human_name_disambiguation_pages',\n",
       " '/wiki/Category:Disambiguation_pages_with_given-name-holder_lists',\n",
       " '/wiki/Category:Short_description_is_different_from_Wikidata',\n",
       " '/wiki/Category:All_article_disambiguation_pages',\n",
       " '/wiki/Category:All_disambiguation_pages',\n",
       " '/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License',\n",
       " '//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use',\n",
       " '//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy',\n",
       " '//www.wikimediafoundation.org/',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy',\n",
       " '/wiki/Wikipedia:About',\n",
       " '/wiki/Wikipedia:General_disclaimer',\n",
       " '//en.wikipedia.org/wiki/Wikipedia:Contact_us',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct',\n",
       " 'https://developer.wikimedia.org',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement',\n",
       " '//en.m.wikipedia.org/w/index.php?title=Python&mobileaction=toggle_view_mobile',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_links = soup4.select('ul li')\n",
    "list_link = []\n",
    "\n",
    "for li in wiki_links:\n",
    "    a_tag = li.find_all('a')\n",
    "    \n",
    "    for a in a_tag:\n",
    "        herf = a.get('href')\n",
    "\n",
    "        if herf:\n",
    "            list_link.append(herf)\n",
    "        \n",
    "list_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 5 - N√∫mero de T√≠tulos que han cambiado en el C√≥digo de los Estados Unidos desde su √∫ltimo punto de lanzamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'\n",
    "indivisual_titles = requests.get(f\"{url}\").text\n",
    "soup5 = BeautifulSoup(indivisual_titles , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_files = soup5.find_all('div', class_='usctitlechanged')\n",
    "len(changed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 6 - Una lista de Python con los diez nombres m√°s buscados por el FBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://en.wikipedia.org/wiki/FBI_Ten_Most_Wanted_Fugitives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = requests.get(f\"{url6}\").text\n",
    "soup6 = BeautifulSoup(wanted, 'html.parser')\n",
    "wantedtag = soup6.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexis Flores\n",
      "Bhadreshkumar Chetanbhai Patel\n",
      "Alejandro Castillo\n",
      "Arnoldo Jimenez\n",
      "Yulan Adonay Archaga Carias\n",
      "Ruja Ignatova\n",
      "Omar Alexander Cardenas\n",
      "Wilver Villegas-Palomino\n",
      "Donald Eugene Fields II\n",
      "Vitel'Homme Innocent\n"
     ]
    }
   ],
   "source": [
    "list_name= []\n",
    "for item in wantedtag:\n",
    "    names = item.find('div', class_='center')\n",
    "\n",
    "    if names is not None:\n",
    "        for name in names:\n",
    "            print(name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 7 - Listar todos los nombres de idiomas y el n√∫mero de art√≠culos relacionados en el orden en que aparecen en wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = requests.get(f\"{url7}\")\n",
    "languages.encoding = 'uft-8'\n",
    "soup7 = BeautifulSoup(languages.text)\n",
    "langlist = soup7.find_all(\"div\", {\"class\": f\"central-featured-lang\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('English', '6796000'),\n",
       " ('–†—É—Å—Å–∫–∏–π', '1969000'),\n",
       " ('Êó•Êú¨Ë™û', '1407000'),\n",
       " ('Espa√±ol', '1938000'),\n",
       " ('Deutsch', '2891000'),\n",
       " ('Fran√ßais', '2598000'),\n",
       " ('Italiano', '1853000'),\n",
       " ('‰∏≠Êñá', '1409000'),\n",
       " ('ŸÅÿßÿ±ÿ≥€å', '€π€π€µ€∞€∞€∞'),\n",
       " ('Portugu√™s', '1120000')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_collect = []\n",
    "for lang in langlist:\n",
    "     language = lang.find('strong').text.strip()\n",
    "     articles = ''.join(filter(str.isdigit, lang.find('small').text.strip()))\n",
    "     languages_collect.append((language, articles))\n",
    "\n",
    "languages_collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 8 - Una lista con los diferentes tipos de conjuntos de datos disponibles en data.gov.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url82 = 'https://data.gov.uk/'\n",
    "dats = requests.get(f\"{url82}\")\n",
    "soup8 = BeautifulSoup(dats.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_links = soup8.select(\"h3:nth-child(1) > a:nth-child(1)\")\n",
    "dataset_types = []\n",
    "for link in dataset_links:\n",
    "    dataset_types.append(link.text.strip())\n",
    "\n",
    "dataset_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 9 - Los 10 idiomas con m√°s hablantes nativos almacenados en un DataFrame de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url9 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'\n",
    "tenlang = requests.get(url9)\n",
    "soup9 = BeautifulSoup(tenlang.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mandarin Chinese', '941', 'Sino-Tibetan', 'Sinitic'],\n",
       " ['Spanish', '486', 'Indo-European', 'Romance'],\n",
       " ['English', '380', 'Indo-European', 'Germanic'],\n",
       " ['Hindi', '345', 'Indo-European', 'Indo-Aryan'],\n",
       " ['Bengali', '237', 'Indo-European', 'Indo-Aryan'],\n",
       " ['Portuguese', '236', 'Indo-European', 'Romance'],\n",
       " ['Russian', '148', 'Indo-European', 'Balto-Slavic'],\n",
       " ['Japanese', '123', 'Japonic', 'Japanese'],\n",
       " ['Yue Chinese', '86', 'Sino-Tibetan', 'Sinitic'],\n",
       " ['Vietnamese', '85', 'Austroasiatic', 'Vietic']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langtable = soup9.find(\"table\", class_='wikitable')\n",
    "langrows = langtable.find_all('tr')\n",
    "langs = []\n",
    "for row in langrows[1:11]:\n",
    "    col=row.find_all('td')\n",
    "    lang=col[0].text.strip()\n",
    "    speakers=col[1].text.strip()\n",
    "    langfamily=col[2].text.strip()\n",
    "    branch=col[3].text.strip()\n",
    "    langs.append([lang,speakers,langfamily,branch])\n",
    "\n",
    "langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subiendo el nivel\n",
    "#### Desaf√≠o 10 - La informaci√≥n de los 20 √∫ltimos terremotos (fecha, hora, latitud, longitud y nombre de la regi√≥n) por el EMSC como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "#url7 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "url10 = \"http://ds.iris.edu/seismon/eventlist/index.phtml\"\n",
    "response = requests.get(url10)\n",
    "soup10 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Mag</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-MAY-2024 14:31:02</td>\n",
       "      <td>36.72</td>\n",
       "      <td>21.66</td>\n",
       "      <td>4.2</td>\n",
       "      <td>48</td>\n",
       "      <td>SOUTHERN GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-MAY-2024 12:02:47</td>\n",
       "      <td>-37.96</td>\n",
       "      <td>-74.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>12</td>\n",
       "      <td>OFF COAST OF CENTRAL CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-MAY-2024 11:52:45</td>\n",
       "      <td>-4.79</td>\n",
       "      <td>133.90</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10</td>\n",
       "      <td>IRIAN JAYA REGION, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-MAY-2024 10:16:33</td>\n",
       "      <td>18.98</td>\n",
       "      <td>-65.48</td>\n",
       "      <td>4.04</td>\n",
       "      <td>54</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-MAY-2024 10:10:39</td>\n",
       "      <td>-18.05</td>\n",
       "      <td>-177.90</td>\n",
       "      <td>4.4</td>\n",
       "      <td>557</td>\n",
       "      <td>FIJI ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25-MAY-2024 08:08:59</td>\n",
       "      <td>56.13</td>\n",
       "      <td>163.72</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32</td>\n",
       "      <td>NEAR EAST COAST OF KAMCHATKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25-MAY-2024 07:52:08</td>\n",
       "      <td>-27.66</td>\n",
       "      <td>-67.81</td>\n",
       "      <td>4.5</td>\n",
       "      <td>141</td>\n",
       "      <td>CATAMARCA PROVINCE, ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25-MAY-2024 07:37:21</td>\n",
       "      <td>1.15</td>\n",
       "      <td>126.44</td>\n",
       "      <td>4.9</td>\n",
       "      <td>41</td>\n",
       "      <td>NORTHERN MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25-MAY-2024 06:56:38</td>\n",
       "      <td>-20.93</td>\n",
       "      <td>-178.52</td>\n",
       "      <td>4.4</td>\n",
       "      <td>539</td>\n",
       "      <td>FIJI ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25-MAY-2024 05:55:51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>131.70</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10</td>\n",
       "      <td>IRIAN JAYA REGION, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25-MAY-2024 05:43:31</td>\n",
       "      <td>-18.05</td>\n",
       "      <td>-178.31</td>\n",
       "      <td>4.3</td>\n",
       "      <td>602</td>\n",
       "      <td>FIJI ISLANDS REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25-MAY-2024 05:03:27</td>\n",
       "      <td>-30.73</td>\n",
       "      <td>-71.84</td>\n",
       "      <td>4.1</td>\n",
       "      <td>29</td>\n",
       "      <td>NEAR COAST OF CENTRAL CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25-MAY-2024 04:33:09</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>154.34</td>\n",
       "      <td>4.9</td>\n",
       "      <td>92</td>\n",
       "      <td>SOLOMON ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25-MAY-2024 02:49:43</td>\n",
       "      <td>30.12</td>\n",
       "      <td>-42.69</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NORTHERN MID-ATLANTIC RIDGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25-MAY-2024 02:20:08</td>\n",
       "      <td>2.36</td>\n",
       "      <td>126.72</td>\n",
       "      <td>4.8</td>\n",
       "      <td>48</td>\n",
       "      <td>NORTHERN MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25-MAY-2024 00:10:13</td>\n",
       "      <td>3.71</td>\n",
       "      <td>94.86</td>\n",
       "      <td>4.9</td>\n",
       "      <td>23</td>\n",
       "      <td>OFF W COAST OF NORTHERN SUMATRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24-MAY-2024 22:51:21</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>134.98</td>\n",
       "      <td>4.6</td>\n",
       "      <td>31</td>\n",
       "      <td>IRIAN JAYA REGION, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24-MAY-2024 18:59:32</td>\n",
       "      <td>51.97</td>\n",
       "      <td>173.88</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10</td>\n",
       "      <td>NEAR ISLANDS, ALEUTIAN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24-MAY-2024 17:35:24</td>\n",
       "      <td>39.32</td>\n",
       "      <td>17.06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>SOUTHERN ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24-MAY-2024 17:07:12</td>\n",
       "      <td>24.20</td>\n",
       "      <td>121.72</td>\n",
       "      <td>4.6</td>\n",
       "      <td>33</td>\n",
       "      <td>TAIWAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date-Time     Lat      Lon   Mag Depth  \\\n",
       "0   25-MAY-2024 14:31:02   36.72    21.66   4.2    48   \n",
       "1   25-MAY-2024 12:02:47  -37.96   -74.00   4.7    12   \n",
       "2   25-MAY-2024 11:52:45   -4.79   133.90   4.6    10   \n",
       "3   25-MAY-2024 10:16:33   18.98   -65.48  4.04    54   \n",
       "4   25-MAY-2024 10:10:39  -18.05  -177.90   4.4   557   \n",
       "5   25-MAY-2024 08:08:59   56.13   163.72   5.0    32   \n",
       "6   25-MAY-2024 07:52:08  -27.66   -67.81   4.5   141   \n",
       "7   25-MAY-2024 07:37:21    1.15   126.44   4.9    41   \n",
       "8   25-MAY-2024 06:56:38  -20.93  -178.52   4.4   539   \n",
       "9   25-MAY-2024 05:55:51    0.81   131.70   4.8    10   \n",
       "10  25-MAY-2024 05:43:31  -18.05  -178.31   4.3   602   \n",
       "11  25-MAY-2024 05:03:27  -30.73   -71.84   4.1    29   \n",
       "12  25-MAY-2024 04:33:09   -5.68   154.34   4.9    92   \n",
       "13  25-MAY-2024 02:49:43   30.12   -42.69   5.0    10   \n",
       "14  25-MAY-2024 02:20:08    2.36   126.72   4.8    48   \n",
       "15  25-MAY-2024 00:10:13    3.71    94.86   4.9    23   \n",
       "16  24-MAY-2024 22:51:21   -1.22   134.98   4.6    31   \n",
       "17  24-MAY-2024 18:59:32   51.97   173.88   4.4    10   \n",
       "18  24-MAY-2024 17:35:24   39.32    17.06   4.0    10   \n",
       "19  24-MAY-2024 17:07:12   24.20   121.72   4.6    33   \n",
       "\n",
       "                           Location  \n",
       "0                   SOUTHERN GREECE  \n",
       "1        OFF COAST OF CENTRAL CHILE  \n",
       "2      IRIAN JAYA REGION, INDONESIA  \n",
       "3                PUERTO RICO REGION  \n",
       "4               FIJI ISLANDS REGION  \n",
       "5      NEAR EAST COAST OF KAMCHATKA  \n",
       "6     CATAMARCA PROVINCE, ARGENTINA  \n",
       "7              NORTHERN MOLUCCA SEA  \n",
       "8               FIJI ISLANDS REGION  \n",
       "9      IRIAN JAYA REGION, INDONESIA  \n",
       "10              FIJI ISLANDS REGION  \n",
       "11      NEAR COAST OF CENTRAL CHILE  \n",
       "12                  SOLOMON ISLANDS  \n",
       "13      NORTHERN MID-ATLANTIC RIDGE  \n",
       "14             NORTHERN MOLUCCA SEA  \n",
       "15  OFF W COAST OF NORTHERN SUMATRA  \n",
       "16     IRIAN JAYA REGION, INDONESIA  \n",
       "17   NEAR ISLANDS, ALEUTIAN ISLANDS  \n",
       "18                   SOUTHERN ITALY  \n",
       "19                           TAIWAN  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqtable = soup10.find(\"table\", class_=\"tablesorter\")\n",
    "eqrows = eqtable.find_all(\"tr\")\n",
    "earthquakes = []\n",
    "\n",
    "for row in eqrows[1:21]:\n",
    "    col=row.find_all(\"td\")\n",
    "    date =col[0].text.strip()\n",
    "    lat =col[1].text.strip()\n",
    "    lon =col[2].text.strip()\n",
    "    mag=col[3].text.strip()\n",
    "    depth=col[4].text.strip()\n",
    "    location=col[5].text.strip()\n",
    "    earthquakes.append([date,lat,lon,mag,depth,location])\n",
    "\n",
    "earthquakes\n",
    "\n",
    "df = pd.DataFrame(earthquakes, columns=[\"Date-Time\", \"Lat\", \"Lon\", \"Mag\",\"Depth\",\"Location\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 11 - Datos del Top 250 de IMDB (nombre de la pel√≠cula, lanzamiento inicial, nombre del director y estrellas) como un dataframe de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url11 = 'https://www.imdb.com/chart/top'\n",
    "pelis = requests.get(url11)\n",
    "soup11 = BeautifulSoup(pelis.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 12 - Nombre de la pel√≠cula, a√±o y un breve resumen de las 10 pel√≠culas aleatorias top (IMDB) como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(soup.find_all(\"span\", {\"class\": \"secondaryInfo\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 13 - Encontrar el reporte meteorol√≥gico en vivo (temperatura, velocidad del viento, descripci√≥n y clima) de una ciudad dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(city):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desaf√≠o 14 - Nombre del libro, precio y disponibilidad de stock como un dataframe de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url14 = 'http://books.toscrape.com/'\n",
    "books = requests.get(url11)\n",
    "soup = BeautifulSoup(books.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libros = list(soup.select('h1.h3 a[tittle]'))\n",
    "#nombres = soup.select('h1.h3 a[tittle]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitates tu output? Gracias! üôÇ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
